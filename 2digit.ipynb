{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/taemmini/2023_Fall_HUFS_ML_Project_7/blob/main/CAPTCHA_Project_CRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nR_wHXafYlSW",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yongh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_with_label(folder_path : str, extension : str):\n",
    "    images = glob(r\".\\resource\\%s\\*.%s\"%(folder_path, extension))\n",
    "    labels = [img.split(os.path.sep)[3].split('.'+extension)[0].split('_')[0] for img in images]\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4881 00\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_image_with_label('2digitGRAY','png')\n",
    "print(len(labels), labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6iRzXLJ2Wqu",
    "outputId": "188d8472-a89b-4e09-b507-7b4dd2eeb2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m', 'b', 'n', 'q', 'j', 'w', 'o', 'e', 'k', 'u', 'h', 'p', 'y', 's', 'x', '7', '9', 'r', 'f', 'l', '1', '2', '8', '0', '6', 'c', '5', 'z', 'g', 't', 'd', 'v', 'a', '3', 'i', '4'}\n",
      "36\n",
      "WARNING:tensorflow:From C:\\Users\\yongh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongh\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "unique_char = set(''.join(labels))\n",
    "print(unique_char)\n",
    "print(len(unique_char))\n",
    "\n",
    "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary = list(unique_char), num_oov_indices = 0, mask_token = None\n",
    ")\n",
    "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary = char_to_num.get_vocabulary(), num_oov_indices = 0, mask_token = None, invert = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnqRxbE58PqB",
    "outputId": "896e5a92-025d-4ecf-f4ec-8abaea194d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4392 489\n",
      "4392 489\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=777)\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "c4jn9mbI9C2q",
    "outputId": "0c3f29ee-59c8-490f-fe46-9e815b03c436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x239c64f7f50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 제대로 매칭되어 있는지 확인\n",
    "sample = cv2.imread(x_train[0])\n",
    "print(y_train[0])\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XIkBHt74D3_o"
   },
   "outputs": [],
   "source": [
    "img_width = 200\n",
    "img_height = 50\n",
    "\n",
    "def encode_image(path, label):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.io.decode_png(img, channels=1)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  img = tf.image.resize(img, [img_height, img_width])\n",
    "  img = tf.transpose(img, perm=[1,0,2])\n",
    "\n",
    "  label = char_to_num(tf.strings.unicode_split(label, input_encoding = 'UTF-8'))\n",
    "\n",
    "  return {'image':img, 'label':label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "Iz7BNKwlGZBT",
    "outputId": "e3e13d27-57ad-459e-e03d-523d2ded777d"
   },
   "outputs": [],
   "source": [
    "# preview = encode_image(images[0], labels[0])\n",
    "# print(labels[0])\n",
    "# print(preview['label'])\n",
    "# plt.imshow(preview['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwhhHWSqHYYs",
    "outputId": "689633f4-24c2-4c21-f9bd-fba5509e146c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yongh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "<_PrefetchDataset element_spec={'image': TensorSpec(shape=(None, 200, 50, 1), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}>\n",
      "<_PrefetchDataset element_spec={'image': TensorSpec(shape=(None, 200, 50, 1), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "# 모델에 넣을 데이터셋 구성(배치 학습이 아니기 때문에 정해진 배치사이즈마다 일정한 양의 데이터 묶음을 넣어 학습 진행)\n",
    "\n",
    "batch_size = 32\n",
    "# tf가 제공하는 Dataset을 사용하는게 학습이 더 빨라서 일반적으로 사용하는 것 같습니다.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        encode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = (\n",
    "    test_dataset.map(\n",
    "        encode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "I3VVIHP6Ipj9"
   },
   "outputs": [],
   "source": [
    "# CTC손실함수 정의 : 정형화된 구현 방법이 존재하여 그대로 가져왔습니다.\n",
    "\n",
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred\n",
    "\n",
    "def build_model():\n",
    "    input_img = layers.Input(\n",
    "        shape=(img_width, img_height, 1), name='image', dtype='float32'\n",
    "    )\n",
    "    labels = layers.Input(name='label', shape=(None,), dtype='float32')\n",
    "\n",
    "    # Convolution, Maxpooling을 각각 두번하여 차원을 축소함\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        activation='relu',\n",
    "        kernel_initializer='he_normal',\n",
    "        padding='same',\n",
    "        name='Conv1',\n",
    "    )(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        activation='relu',\n",
    "        kernel_initializer='he_normal',\n",
    "        padding='same',\n",
    "        name='Conv2',\n",
    "    )(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
    "\n",
    "    new_shape = ((img_width // 4), (img_height // 4) * 64)\n",
    "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
    "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # RNN을 두 차례 사용\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "    # 출력층 구성\n",
    "    x = layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 1, activation='softmax', name='dense2'\n",
    "    )(x)\n",
    "\n",
    "    # CTC 손실함수 적용\n",
    "    output = CTCLayer(name='ctc_loss')(labels, x)\n",
    "\n",
    "    # 모델 구성\n",
    "    model = keras.models.Model(\n",
    "        inputs=[input_img, labels], outputs=output, name='ocr_model_v1'\n",
    "    )\n",
    "    # 케라스에서 제공하는 최적화\n",
    "    opt = keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dl0epy3WLKAH",
    "outputId": "fcba5020-53fc-4647-8a99-963f440f738a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "138/138 [==============================] - 13s 65ms/step - loss: 11.1430 - val_loss: 8.4501\n",
      "Epoch 2/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 8.3737 - val_loss: 8.1563\n",
      "Epoch 3/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.8512 - val_loss: 7.5602\n",
      "Epoch 4/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.5065 - val_loss: 7.4658\n",
      "Epoch 5/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4596 - val_loss: 7.4587\n",
      "Epoch 6/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4469 - val_loss: 7.4539\n",
      "Epoch 7/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4386 - val_loss: 7.4534\n",
      "Epoch 8/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4356 - val_loss: 7.4547\n",
      "Epoch 9/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4285 - val_loss: 7.4513\n",
      "Epoch 10/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4266 - val_loss: 7.4512\n",
      "Epoch 11/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4227 - val_loss: 7.4494\n",
      "Epoch 12/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4231 - val_loss: 7.4500\n",
      "Epoch 13/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 7.4185 - val_loss: 7.4498\n",
      "Epoch 14/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4184 - val_loss: 7.4492\n",
      "Epoch 15/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4175 - val_loss: 7.4500\n",
      "Epoch 16/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4145 - val_loss: 7.4501\n",
      "Epoch 17/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4144 - val_loss: 7.4491\n",
      "Epoch 18/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4133 - val_loss: 7.4506\n",
      "Epoch 19/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4112 - val_loss: 7.4491\n",
      "Epoch 20/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4133 - val_loss: 7.4486\n",
      "Epoch 21/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4109 - val_loss: 7.4484\n",
      "Epoch 22/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.4093 - val_loss: 7.4496\n",
      "Epoch 23/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4102 - val_loss: 7.4488\n",
      "Epoch 24/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 7.4095 - val_loss: 7.4486\n",
      "Epoch 25/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 7.4079 - val_loss: 7.4469\n",
      "Epoch 26/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 7.4079 - val_loss: 7.4467\n",
      "Epoch 27/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4091 - val_loss: 7.4464\n",
      "Epoch 28/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 7.4079 - val_loss: 7.4488\n",
      "Epoch 29/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4081 - val_loss: 7.4484\n",
      "Epoch 30/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4079 - val_loss: 7.4457\n",
      "Epoch 31/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.4059 - val_loss: 7.4462\n",
      "Epoch 32/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4070 - val_loss: 7.4459\n",
      "Epoch 33/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 7.4063 - val_loss: 7.4461\n",
      "Epoch 34/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 7.4072 - val_loss: 7.4463\n",
      "Epoch 35/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 7.4068 - val_loss: 7.4474\n",
      "Epoch 36/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4058 - val_loss: 7.4473\n",
      "Epoch 37/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4050 - val_loss: 7.4471\n",
      "Epoch 38/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.4053 - val_loss: 7.4464\n",
      "Epoch 39/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.4053 - val_loss: 7.4468\n",
      "Epoch 40/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 7.4035 - val_loss: 7.4478\n",
      "Epoch 41/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4046 - val_loss: 7.4469\n",
      "Epoch 42/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 7.4021 - val_loss: 7.4458\n",
      "Epoch 43/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.4051 - val_loss: 7.4488\n",
      "Epoch 44/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.4015 - val_loss: 7.4449\n",
      "Epoch 45/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.4002 - val_loss: 7.4468\n",
      "Epoch 46/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 7.4013 - val_loss: 7.4464\n",
      "Epoch 47/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 7.3953 - val_loss: 7.4448\n",
      "Epoch 48/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.3950 - val_loss: 7.4612\n",
      "Epoch 49/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 7.2601 - val_loss: 6.9575\n",
      "Epoch 50/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 6.8870 - val_loss: 6.6411\n",
      "Epoch 51/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 6.3112 - val_loss: 5.7889\n",
      "Epoch 52/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 5.5644 - val_loss: 5.2531\n",
      "Epoch 53/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 5.1123 - val_loss: 4.9518\n",
      "Epoch 54/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 4.7548 - val_loss: 4.4778\n",
      "Epoch 55/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 4.4191 - val_loss: 4.1757\n",
      "Epoch 56/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 4.0566 - val_loss: 3.8466\n",
      "Epoch 57/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 3.7392 - val_loss: 3.5917\n",
      "Epoch 58/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 3.4352 - val_loss: 3.2210\n",
      "Epoch 59/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 3.1953 - val_loss: 2.9382\n",
      "Epoch 60/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 2.9490 - val_loss: 2.8892\n",
      "Epoch 61/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 2.7504 - val_loss: 2.4614\n",
      "Epoch 62/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 2.4899 - val_loss: 2.3550\n",
      "Epoch 63/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 2.3282 - val_loss: 2.0937\n",
      "Epoch 64/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 2.1203 - val_loss: 1.8800\n",
      "Epoch 65/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 1.9700 - val_loss: 1.7321\n",
      "Epoch 66/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 1.7737 - val_loss: 1.5868\n",
      "Epoch 67/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 1.5825 - val_loss: 1.2954\n",
      "Epoch 68/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 1.4357 - val_loss: 1.1633\n",
      "Epoch 69/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 1.3078 - val_loss: 1.0517\n",
      "Epoch 70/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 1.1486 - val_loss: 0.9249\n",
      "Epoch 71/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.9914 - val_loss: 0.7905\n",
      "Epoch 72/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.9356 - val_loss: 0.7142\n",
      "Epoch 73/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.8470 - val_loss: 0.7008\n",
      "Epoch 74/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.7470 - val_loss: 0.5637\n",
      "Epoch 75/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.7309 - val_loss: 0.5769\n",
      "Epoch 76/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.6894 - val_loss: 0.5773\n",
      "Epoch 77/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.6067 - val_loss: 0.5113\n",
      "Epoch 78/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.5688 - val_loss: 0.4383\n",
      "Epoch 79/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.5136 - val_loss: 0.4302\n",
      "Epoch 80/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.5014 - val_loss: 0.3956\n",
      "Epoch 81/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.4598 - val_loss: 0.4221\n",
      "Epoch 82/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.4520 - val_loss: 0.3589\n",
      "Epoch 83/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.4560 - val_loss: 0.3516\n",
      "Epoch 84/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.4003 - val_loss: 0.3679\n",
      "Epoch 85/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.3884 - val_loss: 0.3405\n",
      "Epoch 86/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.3976 - val_loss: 0.3084\n",
      "Epoch 87/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.3833 - val_loss: 0.3192\n",
      "Epoch 88/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.3575 - val_loss: 0.2694\n",
      "Epoch 89/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.3289 - val_loss: 0.2532\n",
      "Epoch 90/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.3204 - val_loss: 0.2933\n",
      "Epoch 91/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.3096 - val_loss: 0.2657\n",
      "Epoch 92/250\n",
      "138/138 [==============================] - 9s 64ms/step - loss: 0.2909 - val_loss: 0.2228\n",
      "Epoch 93/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.2774 - val_loss: 0.2475\n",
      "Epoch 94/250\n",
      "138/138 [==============================] - 9s 65ms/step - loss: 0.2512 - val_loss: 0.1807\n",
      "Epoch 95/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.2336 - val_loss: 0.1998\n",
      "Epoch 96/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.2842 - val_loss: 0.2278\n",
      "Epoch 97/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.2191 - val_loss: 0.1848\n",
      "Epoch 98/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.2185 - val_loss: 0.2285\n",
      "Epoch 99/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.2003 - val_loss: 0.1628\n",
      "Epoch 100/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.2137 - val_loss: 0.2071\n",
      "Epoch 101/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.2042 - val_loss: 0.1508\n",
      "Epoch 102/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.2152 - val_loss: 0.1681\n",
      "Epoch 103/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.2345 - val_loss: 0.1657\n",
      "Epoch 104/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.1813 - val_loss: 0.1577\n",
      "Epoch 105/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1954 - val_loss: 0.1815\n",
      "Epoch 106/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.2090 - val_loss: 0.1457\n",
      "Epoch 107/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1502 - val_loss: 0.1616\n",
      "Epoch 108/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.1598 - val_loss: 0.1607\n",
      "Epoch 109/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1837 - val_loss: 0.1791\n",
      "Epoch 110/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1390 - val_loss: 0.1498\n",
      "Epoch 111/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1594 - val_loss: 0.1670\n",
      "Epoch 112/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1437 - val_loss: 0.1850\n",
      "Epoch 113/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1605 - val_loss: 0.1375\n",
      "Epoch 114/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1181 - val_loss: 0.0840\n",
      "Epoch 115/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.1273 - val_loss: 0.1228\n",
      "Epoch 116/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1427 - val_loss: 0.1785\n",
      "Epoch 117/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.1466 - val_loss: 0.1008\n",
      "Epoch 118/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1607 - val_loss: 0.1651\n",
      "Epoch 119/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.1249 - val_loss: 0.1416\n",
      "Epoch 120/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1257 - val_loss: 0.1345\n",
      "Epoch 121/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1128 - val_loss: 0.1488\n",
      "Epoch 122/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1030 - val_loss: 0.0966\n",
      "Epoch 123/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.1039 - val_loss: 0.0892\n",
      "Epoch 124/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0897 - val_loss: 0.2251\n",
      "Epoch 125/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.1057 - val_loss: 0.1049\n",
      "Epoch 126/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0706 - val_loss: 0.1586\n",
      "Epoch 127/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.1171 - val_loss: 0.1204\n",
      "Epoch 128/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.1008 - val_loss: 0.1630\n",
      "Epoch 129/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0974 - val_loss: 0.1371\n",
      "Epoch 130/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0728 - val_loss: 0.0947\n",
      "Epoch 131/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0821 - val_loss: 0.1209\n",
      "Epoch 132/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.1119 - val_loss: 0.1849\n",
      "Epoch 133/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0973 - val_loss: 0.1091\n",
      "Epoch 134/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0790 - val_loss: 0.1513\n",
      "Epoch 135/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0870 - val_loss: 0.1295\n",
      "Epoch 136/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.1135 - val_loss: 0.1377\n",
      "Epoch 137/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.1087 - val_loss: 0.1051\n",
      "Epoch 138/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0863 - val_loss: 0.1227\n",
      "Epoch 139/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0858 - val_loss: 0.1133\n",
      "Epoch 140/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0773 - val_loss: 0.1604\n",
      "Epoch 141/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0712 - val_loss: 0.1216\n",
      "Epoch 142/250\n",
      "138/138 [==============================] - 9s 64ms/step - loss: 0.0797 - val_loss: 0.0927\n",
      "Epoch 143/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0834 - val_loss: 0.1204\n",
      "Epoch 144/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0770 - val_loss: 0.0728\n",
      "Epoch 145/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0675 - val_loss: 0.0763\n",
      "Epoch 146/250\n",
      "138/138 [==============================] - 8s 57ms/step - loss: 0.0850 - val_loss: 0.0902\n",
      "Epoch 147/250\n",
      "138/138 [==============================] - 8s 57ms/step - loss: 0.0763 - val_loss: 0.1423\n",
      "Epoch 148/250\n",
      "138/138 [==============================] - 8s 57ms/step - loss: 0.0743 - val_loss: 0.1098\n",
      "Epoch 149/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0753 - val_loss: 0.1713\n",
      "Epoch 150/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0738 - val_loss: 0.1137\n",
      "Epoch 151/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0615 - val_loss: 0.1194\n",
      "Epoch 152/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0658 - val_loss: 0.1096\n",
      "Epoch 153/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0702 - val_loss: 0.1372\n",
      "Epoch 154/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0659 - val_loss: 0.0906\n",
      "Epoch 155/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0587 - val_loss: 0.1438\n",
      "Epoch 156/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0667 - val_loss: 0.1433\n",
      "Epoch 157/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0930 - val_loss: 0.1333\n",
      "Epoch 158/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0802 - val_loss: 0.0936\n",
      "Epoch 159/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0631 - val_loss: 0.1075\n",
      "Epoch 160/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0519 - val_loss: 0.1092\n",
      "Epoch 161/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0561 - val_loss: 0.1777\n",
      "Epoch 162/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0518 - val_loss: 0.1304\n",
      "Epoch 163/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0493 - val_loss: 0.1333\n",
      "Epoch 164/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0696 - val_loss: 0.1779\n",
      "Epoch 165/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0535 - val_loss: 0.1319\n",
      "Epoch 166/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0582 - val_loss: 0.0971\n",
      "Epoch 167/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0523 - val_loss: 0.1550\n",
      "Epoch 168/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0649 - val_loss: 0.1147\n",
      "Epoch 169/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0537 - val_loss: 0.1575\n",
      "Epoch 170/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0753 - val_loss: 0.1410\n",
      "Epoch 171/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0795 - val_loss: 0.1541\n",
      "Epoch 172/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0500 - val_loss: 0.0866\n",
      "Epoch 173/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0336 - val_loss: 0.0901\n",
      "Epoch 174/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0739 - val_loss: 0.0954\n",
      "Epoch 175/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0548 - val_loss: 0.0985\n",
      "Epoch 176/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 0.0388 - val_loss: 0.1047\n",
      "Epoch 177/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0726 - val_loss: 0.1121\n",
      "Epoch 178/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0486 - val_loss: 0.1921\n",
      "Epoch 179/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0501 - val_loss: 0.1484\n",
      "Epoch 180/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0548 - val_loss: 0.1033\n",
      "Epoch 181/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 0.0661 - val_loss: 0.1189\n",
      "Epoch 182/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0463 - val_loss: 0.1038\n",
      "Epoch 183/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0341 - val_loss: 0.0786\n",
      "Epoch 184/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0378 - val_loss: 0.1093\n",
      "Epoch 185/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0277 - val_loss: 0.1299\n",
      "Epoch 186/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0440 - val_loss: 0.1032\n",
      "Epoch 187/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0546 - val_loss: 0.1870\n",
      "Epoch 188/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0585 - val_loss: 0.1112\n",
      "Epoch 189/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0497 - val_loss: 0.1315\n",
      "Epoch 190/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 0.0435 - val_loss: 0.0710\n",
      "Epoch 191/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0586 - val_loss: 0.0628\n",
      "Epoch 192/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0303 - val_loss: 0.1514\n",
      "Epoch 193/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0400 - val_loss: 0.1392\n",
      "Epoch 194/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0410 - val_loss: 0.1105\n",
      "Epoch 195/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0591 - val_loss: 0.0885\n",
      "Epoch 196/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0475 - val_loss: 0.1065\n",
      "Epoch 197/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0368 - val_loss: 0.0952\n",
      "Epoch 198/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0659 - val_loss: 0.0950\n",
      "Epoch 199/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0428 - val_loss: 0.0820\n",
      "Epoch 200/250\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.0362 - val_loss: 0.1271\n",
      "Epoch 201/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0457 - val_loss: 0.0826\n",
      "Epoch 202/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0504 - val_loss: 0.1202\n",
      "Epoch 203/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0549 - val_loss: 0.0728\n",
      "Epoch 204/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0312 - val_loss: 0.1248\n",
      "Epoch 205/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0434 - val_loss: 0.1062\n",
      "Epoch 206/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0456 - val_loss: 0.1148\n",
      "Epoch 207/250\n",
      "138/138 [==============================] - 9s 64ms/step - loss: 0.0460 - val_loss: 0.1127\n",
      "Epoch 208/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0559 - val_loss: 0.0742\n",
      "Epoch 209/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 0.0598 - val_loss: 0.1318\n",
      "Epoch 210/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0235 - val_loss: 0.0975\n",
      "Epoch 211/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0268 - val_loss: 0.1167\n",
      "Epoch 212/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0244 - val_loss: 0.1020\n",
      "Epoch 213/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0361 - val_loss: 0.1259\n",
      "Epoch 214/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0313 - val_loss: 0.1385\n",
      "Epoch 215/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0584 - val_loss: 0.1104\n",
      "Epoch 216/250\n",
      "138/138 [==============================] - 9s 64ms/step - loss: 0.0486 - val_loss: 0.0930\n",
      "Epoch 217/250\n",
      "138/138 [==============================] - 9s 65ms/step - loss: 0.0635 - val_loss: 0.0890\n",
      "Epoch 218/250\n",
      "138/138 [==============================] - 9s 64ms/step - loss: 0.0246 - val_loss: 0.0868\n",
      "Epoch 219/250\n",
      "138/138 [==============================] - 9s 65ms/step - loss: 0.0322 - val_loss: 0.0796\n",
      "Epoch 220/250\n",
      "138/138 [==============================] - 9s 63ms/step - loss: 0.0646 - val_loss: 0.1055\n",
      "Epoch 221/250\n",
      "138/138 [==============================] - 9s 66ms/step - loss: 0.0554 - val_loss: 0.0959\n",
      "Epoch 222/250\n",
      "138/138 [==============================] - 10s 70ms/step - loss: 0.0352 - val_loss: 0.1390\n",
      "Epoch 223/250\n",
      "138/138 [==============================] - 10s 69ms/step - loss: 0.0323 - val_loss: 0.1043\n",
      "Epoch 224/250\n",
      "138/138 [==============================] - 9s 68ms/step - loss: 0.0410 - val_loss: 0.0973\n",
      "Epoch 225/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0286 - val_loss: 0.1249\n",
      "Epoch 226/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0254 - val_loss: 0.1293\n",
      "Epoch 227/250\n",
      "138/138 [==============================] - 9s 65ms/step - loss: 0.0288 - val_loss: 0.1224\n",
      "Epoch 228/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0165 - val_loss: 0.1867\n",
      "Epoch 229/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0414 - val_loss: 0.1139\n",
      "Epoch 230/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0553 - val_loss: 0.0937\n",
      "Epoch 231/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0245 - val_loss: 0.1085\n",
      "Epoch 232/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0327 - val_loss: 0.1469\n",
      "Epoch 233/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0445 - val_loss: 0.1374\n",
      "Epoch 234/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0259 - val_loss: 0.1611\n",
      "Epoch 235/250\n",
      "138/138 [==============================] - 9s 62ms/step - loss: 0.0265 - val_loss: 0.0980\n",
      "Epoch 236/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0391 - val_loss: 0.1014\n",
      "Epoch 237/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0362 - val_loss: 0.1287\n",
      "Epoch 238/250\n",
      "138/138 [==============================] - 8s 59ms/step - loss: 0.0299 - val_loss: 0.1144\n",
      "Epoch 239/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0359 - val_loss: 0.1321\n",
      "Epoch 240/250\n",
      "138/138 [==============================] - 8s 60ms/step - loss: 0.0255 - val_loss: 0.1038\n",
      "Epoch 241/250\n",
      "138/138 [==============================] - 8s 61ms/step - loss: 0.0462 - val_loss: 0.1219\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "epochs = 250\n",
    "stopping_patience = 50\n",
    "#restore_best_weights : 조기종료 후 지금까지 최적값을 냈던 가중치를 다시 선택함\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=stopping_patience, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = test_dataset,\n",
    "    epochs = epochs,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./2digitModel1.keras')\n",
    "model.save_weights('./2digitModel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_length = [len(label) for label in labels]\n",
    "max_length = max(label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :max_length]\n",
    "    output_text = []\n",
    "    # encode된 글자를 복원하여 리스트에 저장\n",
    "    for res in results:\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode('utf-8')\n",
    "        output_text.append(res)\n",
    "    return output_text\n",
    "\n",
    "def encode_image_only(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.io.decode_png(img, channels=1)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  img = tf.image.resize(img, [img_height, img_width])\n",
    "  img = tf.transpose(img, perm=[1,0,2])\n",
    "    \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = keras.models.Model(\n",
    "  model.get_layer(name='image').input, model.get_layer(name='dense2').output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_sample_image(model, path : str, label):\n",
    "    image_tensor = encode_image_only(path)\n",
    "    image_tensor = tf.expand_dims(image_tensor,0)\n",
    "    pred = model.predict(image_tensor)\n",
    "    pred_text = decode_batch_predictions(pred)\n",
    "    print('prediction :',pred_text[0],' / ','Actual label :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23', '23', '3q', '3q', '46', '46', '52', '52', '7d', '7d', '7n', '7n', '8z', '8z', '9b', '9b', 'a6', 'a6', 'am', 'am', 'bh', 'bh', 'cv', 'cv', 'e4', 'e4', 'mg', 'mg', 'mq', 'mq', 'n7', 'n7', 'nh', 'nh', 'p5', 'p5', 'pv', 'pv', 'qu', 'qu', 'vg', 'vg', 'x4', 'x4', 'xp', 'xp', 'xy', 'xy', 'yd', 'yd', 'z4', 'z4', 'zx', 'zx']\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels = images, labels = load_image_with_label('Test_Denoised','jpg')\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 860ms/step\n",
      "prediction : g3  /  Actual label : 23\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "prediction : 23  /  Actual label : 23\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 3q  /  Actual label : 3q\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "prediction : 34  /  Actual label : 3q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 8o  /  Actual label : 46\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 9o  /  Actual label : 46\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : 53  /  Actual label : 52\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 8g  /  Actual label : 52\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 74  /  Actual label : 7d\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : dq  /  Actual label : 7d\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 4m  /  Actual label : 7n\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 4m  /  Actual label : 7n\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : u3  /  Actual label : 8z\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : be  /  Actual label : 8z\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : db  /  Actual label : 9b\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : d8  /  Actual label : 9b\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : c6  /  Actual label : a6\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : 38  /  Actual label : a6\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : cp  /  Actual label : am\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : 9o  /  Actual label : am\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : b9  /  Actual label : bh\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : b9  /  Actual label : bh\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : o5  /  Actual label : cv\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 6o  /  Actual label : cv\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 94  /  Actual label : e4\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : ko  /  Actual label : e4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : m3  /  Actual label : mg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : mg  /  Actual label : mg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : q[UNK]  /  Actual label : mq\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : mq  /  Actual label : mq\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 45  /  Actual label : n7\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : n4  /  Actual label : n7\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : m6  /  Actual label : nh\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : mo  /  Actual label : nh\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : p5  /  Actual label : p5\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : b5  /  Actual label : p5\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "prediction : bo  /  Actual label : pv\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : uq  /  Actual label : pv\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : qd  /  Actual label : qu\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : dq  /  Actual label : qu\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : p3  /  Actual label : vg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : 63  /  Actual label : vg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : 54  /  Actual label : x4\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : 9[UNK]  /  Actual label : x4\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 5q  /  Actual label : xp\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : uo  /  Actual label : xp\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 56  /  Actual label : xy\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : 56  /  Actual label : xy\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : s4  /  Actual label : yd\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : w4  /  Actual label : yd\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "prediction : a3  /  Actual label : z4\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "prediction : wq  /  Actual label : z4\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : z5  /  Actual label : zx\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "prediction : e3  /  Actual label : zx\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_labels)):\n",
    "    test_with_sample_image(prediction_model,test_images[i],test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtVv1LESr7zJB2Ue2RX+Y6",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
