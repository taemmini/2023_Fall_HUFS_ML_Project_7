{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 불러오기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a43cc750c5fc71ce"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:14.521230Z",
     "start_time": "2023-12-07T16:22:07.970696Z"
    }
   },
   "id": "38a61097fa2ecd16"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# CTCLayer 클래스 정의\n",
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:15.462478Z",
     "start_time": "2023-12-07T16:22:15.453036Z"
    }
   },
   "id": "8f0e7d8eefae75f0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 01:22:20.191937: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-08 01:22:20.191985: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-12-08 01:22:20.191996: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-12-08 01:22:20.192399: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-08 01:22:20.192703: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "with keras.utils.CustomObjectScope({'CTCLayer': CTCLayer}):\n",
    "    model_path = 'CAPTCHA_CRNN_model(Dataset_C,batch_size=32,normalized,lr=0.01).h5'\n",
    "    model = keras.models.load_model(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:21.253276Z",
     "start_time": "2023-12-07T16:22:20.164066Z"
    }
   },
   "id": "a2c778f35563522b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 데이터셋 경로 및 기타 파라미터 설정\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path('char_wemakeprice')\n",
    "img_height = 50\n",
    "img_width = 200\n",
    "batch_size = 32\n",
    "\n",
    "# 이미지와 레이블 리스트 로드\n",
    "images = sorted(list(map(str, dataset_path.glob(\"*.png\"))))\n",
    "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n",
    "\n",
    "# 레이블에서 고유한 문자들 추출 및 매핑\n",
    "characters = set(char for label in labels for char in label)\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "char_to_num = layers.StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "num_to_char = layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n",
    "\n",
    "max_length = max([len(label) for label in labels])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:21.796839Z",
     "start_time": "2023-12-07T16:22:21.767669Z"
    }
   },
   "id": "1ee1b4ce89ba7ea5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 이미지 전처리 함수 정의\n",
    "def encode_single_sample(img_path, label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    padding_size = max_length - tf.shape(label)[0]\n",
    "    padding = tf.zeros(padding_size, dtype=label.dtype)\n",
    "    label = tf.concat([label, padding], axis=0)\n",
    "    return {\"image\": img, \"label\": label}\n",
    "\n",
    "# TensorFlow 데이터셋 생성 및 전처리\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "dataset = dataset.map(encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.batch(batch_size).shuffle(buffer_size=len(images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:22.424455Z",
     "start_time": "2023-12-07T16:22:22.350604Z"
    }
   },
   "id": "a47958d39c6e9c04"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 01:22:23.643983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 66.9967\n",
      "Loss: 66.99674987792969\n"
     ]
    }
   ],
   "source": [
    "# 모델 성능 평가\n",
    "results = model.evaluate(dataset)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Loss: {results}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:24.483534Z",
     "start_time": "2023-12-07T16:22:23.137456Z"
    }
   },
   "id": "f72eaf0e871c4b6b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 200, 50, 1)]      0         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 200, 50, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 200, 50, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 100, 25, 32)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 100, 25, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 100, 25, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 50, 12, 64)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 50, 768)           0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 50, 64)            49216     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50, 64)            0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 50, 256)           197632    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirecti  (None, 50, 128)           164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 50, 62)            7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 438398 (1.67 MB)\n",
      "Trainable params: 438206 (1.67 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "prediction_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:26.888491Z",
     "start_time": "2023-12-07T16:22:26.839510Z"
    }
   },
   "id": "cf00fed7789642d4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 예측 함수 정의\n",
    "def predict(model, batch):\n",
    "    prediction = model.predict(batch)\n",
    "    # 모델의 출력값을 문자열로 변환\n",
    "    output = tf.keras.backend.ctc_decode(\n",
    "        prediction, input_length=np.ones(prediction.shape[0]) * prediction.shape[1], greedy=True\n",
    "    )[0][0]\n",
    "    # 변환된 문자열을 숫자로 변환\n",
    "    out = tf.keras.backend.get_value(output)\n",
    "    # 숫자를 문자로 변환\n",
    "    result = []\n",
    "    for i in out:\n",
    "        result.append(num_to_char(i))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:28.963152Z",
     "start_time": "2023-12-07T16:22:28.958878Z"
    }
   },
   "id": "ee70c16dd4f38d32"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 877ms/step\n",
      "Labels: \n",
      "7en4c\n",
      "8b3g7\n",
      "b2chc\n",
      "fy252\n",
      "gkpg7\n",
      "hgn3n\n",
      "hwmxw\n",
      "knm8d\n",
      "pd4ed\n",
      "rbdc2\n",
      "Predictions: \n",
      "tf.Tensor(\n",
      "[b'e' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'c' b'[UNK]' b'4' b'[UNK]' b'b' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'3' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'3' b'7' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'b' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'[UNK]' b'c' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
      " b'[UNK]' b'[UNK]'], shape=(50,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과 출력\n",
    "for batch in dataset.take(1):\n",
    "    batch_images = batch[\"image\"]\n",
    "    batch_labels = batch[\"label\"]\n",
    "\n",
    "    preds = predict(prediction_model, batch_images)\n",
    "\n",
    "    print(\"Labels: \")\n",
    "    for label in batch_labels:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        print(label)\n",
    "\n",
    "    print(\"Predictions: \")\n",
    "    for pred in preds:\n",
    "        print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:22:30.296307Z",
     "start_time": "2023-12-07T16:22:29.325055Z"
    }
   },
   "id": "92c5f547bbb92a32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
